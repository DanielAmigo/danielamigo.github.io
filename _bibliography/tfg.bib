#####################################################################
# TFGs 20-21
#####################################################################
@phdthesis{hernandez_velasquez_control_2021,
  address		   = {Leganés},
  type			   = {Grado {Universitario} en {Ingeniería} {Electrónica} {Industrial} y {Automática}},
  title			   = {Control mediante la mirada de una cámara integrada en un dron},
  copyright	   = {All rights reserved},
  language	   = {es},
  school		   = {Universidad Carlos III de Madrid},
  author		   = {Hernández Velásquez, Melina Abril},
  collaborator = {Amigo, Daniel},
  month			   = sep,
  year			   = {2021},
  file			   = {theses/hernández_velásquez_2021_control_mediante_la_mirada_de_una_cámara_integrada_en_un_dron.pdf},
}

@phdthesis{romero_urena_deteccion_2021,
  address      = {Colmenarejo},
  type         = {Grado en {Ingeniería} {Informática}},
  title        = {Detección y geolocalización de objetos mediante visión artificial desde vehículos en movimiento},
  copyright    = {All rights reserved},
  language     = {es},
  school       = {Universidad Carlos III de Madrid},
  author       = {Romero Ureña, Daniel},
  collaborator = {Amigo, Daniel},
  month        = sep,
  year         = {2021},
  file         = {theses/romero_ureña_2021_detección_y_geolocalización_de_objetos_mediante_visión_artificial_desde.pdf},
}

@phdthesis{xu_metodologifotogrametripara_2021,
  address      = {Colmenarejo},
  type         = {Grado en {Ingeniería} {Informática}},
  title        = {Metodología de fotogrametría para {UAVs} en entornos simulados},
  copyright    = {All rights reserved},
  language     = {es},
  school       = {Universidad Carlos III de Madrid},
  author       = {Xu, Mengchao},
  collaborator = {Amigo, Daniel},
  month        = sep,
  year         = {2021},
  file         = {theses/xu_2021_metodología_de_fotogrametría_para_uavs_en_entornos_simulados.pdf},
}

@phdthesis{gonzalez_diaz-tendero_metodologipara_2021,
  address      = {Leganés},
  type         = {Grado en {Ingeniería} {Informática}},
  title        = {Metodología para la representación virtual de entornos y objetos del mundo real},
  copyright    = {All rights reserved},
  language     = {es},
  school       = {Universidad Carlos III de Madrid},
  author       = {González Díaz-Tendero, Ignacio},
  collaborator = {Amigo, Daniel},
  month        = jul,
  year         = {2021},
  file         = {theses/gonzález_díaz-tendero_2021_metodología_para_la_representación_virtual_de_entornos_y_objetos_del_mundo_real.pdf},
}

@phdthesis{castellano_berki_estudio_2021,
  address      = {Colmenarejo},
  type         = {Grado en {Ingeniería} {Informática}},
  title        = {Estudio sobre la detección y geolocalización de árboles mediante {LiDAR} e imagen aérea},
  copyright    = {All rights reserved},
  language     = {es},
  school       = {Universidad Carlos III de Madrid},
  author       = {Castellano Berki, Mario},
  collaborator = {Amigo, Daniel},
  month        = jul,
  year         = {2021},
  file         = {theses/castellano_berki_2021_estudio_sobre_la_detección_y_geolocalización_de_árboles_mediante_lidar_e_imagen.pdf},
}

@phdthesis{garcia-maurino_villanueva_alisis_2021,
  address      = {Leganés},
  type         = {Grado en {Ingeniería} {Electrónica} {Industrial} y {Automática}},
  title        = {Análisis de clasificación del terreno mediante imagen satelital},
  copyright    = {All rights reserved},
  language     = {es},
  school       = {Universidad Carlos III de Madrid},
  author       = {García-Mauriño Villanueva, Carlos},
  collaborator = {Amigo, Daniel},
  month        = jul,
  year         = {2021},
  file         = {theses/garcía-mauriño_villanueva_2021_análisis_de_clasificación_del_terreno_mediante_imagen_satelital.pdf},
}

#####################################################################
# TFGs 21-22 Junio
#####################################################################
@phdthesis{tfg_21_22_1,
  address      = {Leganés},
  type         = {Grado en {Ingeniería} {Informática}},
  title        = {Reconstrucción y Análisis de Objetos 3D con UAV},
  abstract     = {La reconstrucción 3D es la disciplina que busca obtener representaciones digitales precisas de objetos del mundo real. Adquiere una gran relevancia en la relación que tienen las personas con los entornos virtuales, permitiendo una interacción realista con los diferentes elementos y aumentando la accesibilidad. Uno de sus usos potenciales se presenta a la hora de generar simulaciones. Estas tienen como objetivo aproximarse con la mayor fidelidad posible a la realidad para poder realizar investigaciones o pruebas, que de ser hechas fuera de la simulación acarrearían riesgos de seguridad o económicos. Los UAV (Unmanned Aerial Vehicle) también conocidos como drones, son vehículos aéreos no tripulados que pueden funcionar de manera autónoma. Estos vehículos tienen la capacidad de optimizar una gran cantidad de procesos debido a su increíble movilidad. Los drones aportan mejoras significativas a las técnicas de reconstrucción 3D puesto que pueden acceder fácilmente a lugares que de otro modo serían inaccesibles y obtener una mayor cantidad de datos del terreno. También se ven beneficiados por esta disciplina ya que las simulaciones dan la posibilidad de diseñar misiones autónomas complejas. Este trabajo presenta una metodología de reconstrucción 3D mediante el uso de drones. Se propone un diseño de misión autónoma con el objetivo de detectar y reconstruir los objetos presentes en un área previamente definida, sin intervención por parte del usuario. El vehículo realiza una recopilación de información sobre el entorno a través de un sensor LIDAR y una cámara RGB. El sistema hace una fusión y procesado de estos datos tanto durante la misión como una vez finalizada, para obtener modelos tridimensionales de los diferentes elementos, su localización geográfica y dimensiones. El proyecto ha sido desarrollado utilizando un entorno de simulación, pero establece las bases para ser implementado en drones reales aplicando mínimas modificaciones. Para evaluar los resultados del sistema, se ha realizado una investigación comparando la metodología de reconstrucción propuesta con dos alternativas distintas. La primera es la aplicación de la fotogrametría clásica basada en la superposición de imágenes de una escena. La segunda es la utilización de modelos de aprendizaje automático capaces de extraer la información tridimensional de las imágenes. Se ha comprobado que la solución propuesta aporta unos resultados óptimos en la geometría de los objetos debido al uso del LIDAR, pero carece de una alta definición en las texturas que sí se obtiene con las otras alternativas. Se determina que la mejor aproximación está en la combinación de múltiples técnicas de reconstrucción para aprovechar las cualidades de cada una.},
  copyright    = {All rights reserved},
  language     = {es},
  school       = {Universidad Carlos III de Madrid},
  author       = {Lizcano Gómez-Calcerrada, Jorge},
  collaborator = {Amigo, Daniel},
  month        = jul,
  year         = {2022},
  file         = {theses/},
}

@phdthesis{tfg_21_22_2,
  address      = {Leganés},
  type         = {Grado en {Ingeniería} {Informática}},
  title        = {Generación automática de réplicas virtuales de carreteras para entornos tridimensionales},
  abstract     = {During the last years, the recreation of real scenarios in virtual environments has become very important in the world of technology and computing with the aim of carrying out simulations in a large number of fields, such as the development of artificial intelligence for the autonomous movement of cars or drones without subjecting prototypes, people or buildings to potential risks.},
  copyright    = {All rights reserved},
  language     = {es},
  school       = {Universidad Carlos III de Madrid},
  author       = {Díaz Fernández, Rubén},
  collaborator = {Amigo, Daniel},
  month        = jul,
  year         = {2022},
  file         = {theses/},
}

@phdthesis{tfg_21_22_3,
  address      = {Colmenarejo},
  type         = {Grado en {Ingeniería} {Informática}},
  title        = {Desarrollo de arquitectura de enjambres de drones descentralizados en entorno simulado},
  abstract     = {Drone swarms are currently a trend, not only for increasing the performance compared to those acting alone, but also for being able to work in a distributed way, generating a completely autonomous collective intelligence, without depending on an intelligent central node that makes them vulnerable to attacks and failures. This work designs and implements an architecture for distributed drone swarm on simulation, using AirSim, PX4, MAVSDK and the Python programming language, the nearest way to simulate real drone flights. The architecture has been tested and verified for swarms of up to 6 drones and several use cases simulating swarm operations have been carried out. Specifically, the drones are able to actively communicate, place themselves in formations in a distributed and collision-free manner, to fly while maintaining the formation, and even to evade obstacles either independently or by helping each other. This work sets the basis for future work on decentralised drone swarms designed and tested entirely in simulation that could be operated in real-world conditions with as little effort as possible.},
  copyright    = {All rights reserved},
  language     = {es},
  school       = {Universidad Carlos III de Madrid},
  author       = {Fornis Herranz, Lázaro},
  collaborator = {Amigo, Daniel},
  month        = jul,
  year         = {2022},
  file         = {theses/},
}

@phdthesis{tfg_21_22_4,
  address      = {Leganés},
  type         = {Grado en {Ingeniería} {Informática}},
  title        = {An Image Classification Approach to Transportation Mode Detection using a CNN},
  abstract     = {Transportation Mode Detection, the ability to identify the vehicle used by a traveler based on GPS and sensor data, has become increasingly relevant thanks to the proliferation of devices capable of recording movement and geolocalization metrics. This paradigm change has allowed the development of countless services and products that rely on transportation mode detection, such as trip planners, food delivery apps or fitness trackers and aided the conduction of refined mobility studies. However, existing implementations require a high degree of expert knowledge, highly impacting ease of deployment. This document describes the Bachelor Thesis with title An Image Classification Approach to Transportation Mode Detection using a CNN. The objective of such thesis is to present an implementation of a machine learning model that, thanks to its Image Based approach, minimizes requirements of Transportation Sciences expert knowledge while remaining capable of outperforming comparable implementations existing on the relevant literature. Firstly, a thorough analysis of the existing literature on Transportation Mode Detection will be carried on, with the purpose of understanding the opportunities for improvement on the field. In addition, a theoretical basis for the technology that supports the proposed model will be laid down. The proposed approach involves the creation of a handcrafted database which encodes the GPS trajectories to classify into image format following an original methodology which will be described in detail. Finally, the proposed model based on a specifically designed Deep Convolutional Neural Network will be presented, stepping through the complete iterative design process that resulted in the final model. The results of the presented experiments show that the proposed model achieves an accuracy of 86.4% in the Transportation Mode Detection task, outperforming most of the existing comparable models. It is proven that the proposed Image Based classification approach can effectively take advantage of the existing and extensive Computer Vision knowledge database to design a model capable of achieving state-ofthe-art performance at a fraction of the cost in Expert Knowledge and complex HandCrafted feature extraction. The proposed approach can serve future implementations that take advantage of transfer learning and perform multimodal trip classification, maximizing its potential and utility.},
  copyright    = {All rights reserved},
  language     = {en},
  school       = {Universidad Carlos III de Madrid},
  author       = {Fariña Salguero, Francisco},
  collaborator = {Amigo, Daniel},
  month        = jul,
  year         = {2022},
  file         = {theses/},
}

#####################################################################
# TFGs 21-22 Septiembre
#####################################################################

@phdthesis{tfg_21_22_5,
  address      = {Leganés},
  type         = {Grado en {Ingeniería} {Informática}},
  title        = {Monitorización de carreteras desde UAVs simulados},
  abstract     = {Drones can provide information that a human cannot see and process it much faster. This is especially useful for road monitoring tasks and to be able to detect vehicles on the roads and the infringements they make. By studying different existing solutions and algorithms, as well as analysing how a drone works, it has been possible to get an idea of how to approach the project. The aim of the work is to be able to estimate the speed of vehicles on a stretch of road by recording it and using computer vision, making use of different algorithms using the OpenCV tool. To apply these algorithms, a video is first needed, which is obtained by means of the drone's camera. Due to the impossibility of testing this project in a real environment, a drone simulator is needed to carry it out, and AirSim using Unreal Engine has been chosen. To provide more realism, the Cesium extension will be used, which provides a map of the world using a geographical view of it. As the work consists of estimating the speed of vehicles travelling along a stretch of a road, the vehicles within the simulation will follow an established path in order to simulate a displacement along that stretch at a speed that will be set as a limit, and will also collect important information for later analysis, such as their speed, position with respect to the drone, position of the drone, etc. Then, using MavSDK and MAVLink to connect the drone to the computer and move it and using the PX4 flight controller software, we are able to carry out an autonomous mission that flies to a section of the road and starts the aforementioned recording to later process the resulting video.},
  copyright    = {All rights reserved},
  language     = {es},
  school       = {Universidad Carlos III de Madrid},
  author       = {Fernández Plaza, Diego},
  collaborator = {Amigo, Daniel},
  month        = sep,
  year         = {2022},
  file         = {theses/},
}

@phdthesis{tfg_21_22_6,
  address      = {Leganés},
  type         = {Grado en {Ingeniería} {Informática}},
  title        = {Detección y geolocalización de objetos automática desde drones},
  abstract     = {In recent years, technology has advanced greatly to the point where small devices such as drones have a wide range of uses. This allows us to think of possible new uses for drones, so that they can facilitate the work of other people or even, in some cases, replace it. On the other hand, there are many ways of mapping streets, either with people capturing images or cars that, as they drive along a street, capture all the details of it. Nor can we forget the growing interest in increasingly advanced artificial intelligences, which allow tasks that were previously unthinkable, such as the recognition of objects in images, to become much simpler tasks.},
  copyright    = {All rights reserved},
  language     = {es},
  school       = {Universidad Carlos III de Madrid},
  author       = {De Alba, Pablo},
  collaborator = {Amigo, Daniel},
  month        = sep,
  year         = {2022},
  file         = {theses/},
}

@phdthesis{tfg_21_22_7,
  address      = {Colmenarejo},
  type         = {Grado en {Ingeniería} {Informática}},
  title        = {Generación y explotación de ortofotografías mediante enjambre de drones simulados},
  abstract     = {This work focuses on aerial reconnaissance drones, specifically, on swarms of drones centralised with photographic capture systems over a given area to generate and analyse orthophotographs in real time. A drone is an unmanned vehicle capable of managing its control autonomously according to the actions to be performed. Drone swarms are often used for aerial reconnaissance, as they can sweep surfaces in less time. Drone swarms are sets of drones that can be anarchic, where there is no central system coordinating the drones' commands, or centralised, where there is a central system. This project is about the creation of an RPAS, Remotely Piloted Aircraft System. The aim of the RPAS is to capture images to generate orthophotographs. Orthophotography is a word formed by the prefix ortho-, meaning straight (perpendicular), and photograph. It is an image of a defined area that has the property that only one perspective (typically the ground plan) is visible so that it can keep the proportions that exist between the elements of the photograph. Orthophotographs are used to analyse terrain surfaces, such as agricultural areas, surface coverages, object recognition... This work focuses on fire detection using artificial intelligence. This analysis is conducted using object detection masks and a convolutional neuron network capable of recognising whether what is in the mask is a fire. The project is conducted using emulation of the environment, as this is the option that allows tests to be conducted with the least loss of resources, so that greater efficiency is obtained. The following tools are used for the drone simulation: Unreal Engine, three-dimensional level engine; Cesium, platform with multiple levels of world zones, to compose realworld scenes; AirSim, a drone simulation software developed by Microsoft, performs hardware emulation of the drone swarm [1]; PX4, open source flight control software running through SITL (Software In The Loop) [3]; and MavSDK, a software development kit for sending and receiving MavLink messages, which acts as a sender and receiver of information between the drone and the central console or control bridge.},
  copyright    = {All rights reserved},
  language     = {es},
  school       = {Universidad Carlos III de Madrid},
  author       = {Tena Blanco, Marcelino},
  collaborator = {Amigo, Daniel},
  month        = sep,
  year         = {2022},
  file         = {theses/},
}

@phdthesis{tfg_21_22_8,
  address      = {Leganés},
  type         = {Grado en {Ingeniería} {Informática}},
  title        = {Mapeado de redes de carreteras mediante inteligencia artificial desde imágenes aéreas},
  abstract     = {Autonomous vehicles are a day-to-day reality, but although significant progress have been made, there is still a long way to go in this technology. Every day more and more companies and research are betting for a future in which transport will be completely autonomous, without the need of human interaction. A variety of technologies are used to allow a vehicle to understand the environment around it in a natural way: active technologies such as cameras, LIDAR sensors, proximity sensors, etc., and passive technologies such as pre-recorded guidelines and routes between locations, and HD Maps. The latter are expensive to generate in terms of time, resources, and money. There are number of companies that market with these technologies of limited areas and regions around the world. However, roads are constantly changing, due to improvements in the road network, changes of signs, works on defects, and a multitude of other reasons. Therefore, the updating of these maps should become a constant task in a very short period in the future, a task that requires a lot of time and human resources to perform manually. With the advancement of artificial intelligence, it will soon be possible to generate models that predict highly accurate information needed to generate HD Maps, such as roads. However, for an artificial intelligence to learn correctly, large amounts of data are necessary for this technology to learn patterns that differentiate a road from what it is not. Here we see a problem: generating large amounts of training data manually in a very short time, therefore, we have researched and developed a system to evaluate the capabilities of the information available in open-source platforms that serves to generate these datasets applicable to the training of Artificial Intelligence for the detection of roads extracted from orthophotos or georeferenced aerial images. In a second part, our system gives the results of the trained models the georeferenced information to be able to proceed to the analysis of the results and, in the future, that can be treated in geographic information systems. Although further research in this field is needed, the results obtained in this work predict that in the future it will be possible and common to use the open-source information available (which will increase in quality and quantity over time) to obtain valid training datasets. This system will save resources and human time in carrying out this arduous and tedious task. A small grain of sand in the automatic generation of layers for HD Maps.},
  copyright    = {All rights reserved},
  language     = {es},
  school       = {Universidad Carlos III de Madrid},
  author       = {Callejo Lara, Mario},
  collaborator = {Amigo, Daniel},
  month        = sep,
  year         = {2022},
  file         = {theses/},
}

#####################################################################
# TFGs 22-23????
#####################################################################

@phdthesis{tfg_21_22_9,
  address      = {Leganés},
  type         = {Grado en {Ingeniería} {Informática}},
  title        = {Indoor mapping desde UAV},
  copyright    = {All rights reserved},
  language     = {es},
  school       = {Universidad Carlos III de Madrid},
  author       = {Fernández Liñán, Rodrigo},
  collaborator = {Amigo, Daniel},
  month        = sep,
  year         = {2022},
  file         = {theses/},
}